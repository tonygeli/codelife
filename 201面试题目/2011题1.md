[toc]



1、自我介绍，项目介绍，遇到的难点？产生原因？如何解决？

### 2、HashMap1.8与1.7区别？ConcurrentHashMap实现原理 ？

HashMap

**组成差别**
1.7:数组+单链表
1.8:数据+单链表+红黑树
**链表存放差别：**
出现哈希冲突时：
1.7直接把数据存放在链表，再无其它操作
1.8把数据存放在链表，链表长度超过8就转红黑树
**扩容差别：**
1.7扩容条件是数组大于阈值且存在哈希冲突时扩容
1.8扩容条件是数组长度大于阈值或链表转红黑树时且数组元素小于64时扩容
**插值方法：**
1.7用的是头插法，(在链表头部插入新值)，弊端：可能造成逆序死循环
1.8用的是尾插法可避免上面的问题

ConcurrentHashMap采用了非常精妙的"分段锁"策略

```java
final Segment<K,V>[] segments;
static class Segment<K,V> extends ReentrantLock;
// 一个Segment维护着一个HashEntry数组
transient volatile HashEntry<K,V>[] table;

public ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel) 
  //MAX_SEGMENTS 为1<<16=65536，也就是最大并发数为65536
  if (concurrencyLevel > MAX_SEGMENTS)
    concurrencyLevel = MAX_SEGMENTS;
	//2的sshif次方等于ssize，例:ssize=16,sshift=4;ssize=32,sshif=5
	int sshift = 0;
	//ssize 为segments数组长度，根据concurrentLevel计算得出
	int ssize = 1;
	while (ssize < concurrencyLevel) {
 	 ++sshift;
  	ssize <<= 1;
	}
```

**Segment数组的大小ssize是由concurrentLevel来决定的，但是却不一定等于concurrentLevel，ssize一定是大于或等于concurrentLevel的最小的2的次幂。比如：默认情况下concurrentLevel是16，则ssize为16；若concurrentLevel为14，ssize为16；若concurrentLevel为17，则ssize为32。**



### 3、jvm类加载器，自定义类加载器，双亲委派机制，优缺点，tomcat类加载机制?

避免类的重复加载， 确保一个类的全局唯一性Java 类随着它的类加载器一起具备了一种带**有优先级的层级关系**， 通过这种层级关系可以避免类的重复加载， 当父亲已经加载了该类时， 就没有必要子ClassLoader 再加载一次

Tomcat各个web应用自己的类加载器(WebAppClassLoader)会优先加载，加载不到时再交给commonClassLoader走双亲委托。

```java
static class ExtClassLoader extends URLClassLoader{
    ... ...
}
static class AppClassLoader extends URLClassLoader{
    ... ...
}
```

二者同时继承了 URLClassLoader ，继承关系如下：

Tomcat 自己实现了自己的类加载器 WebAppClassLoader。

1. 先在本地cache查找该类是否已经加载过，看看 Tomcat 有没有加载过这个类。
2. 如果Tomcat 没有加载过这个类，则从系统类加载器的cache中查找是否加载过。
3. 如果没有加载过这个类，尝试用ExtClassLoader类加载器类加载，重点来了，这里并没有首先使用 AppClassLoader 来加载类。这个Tomcat 的 WebAPPClassLoader 违背了双亲委派机制，直接使用了 ExtClassLoader来加载类。这里注意 ExtClassLoader 双亲委派依然有效，ExtClassLoader 就会使用 Bootstrap ClassLoader 来对类进行加载，保证了 Jre 里面的核心类不会被重复加载。 比如在 Web 中加载一个 Object 类。WebAppClassLoader → ExtClassLoader → Bootstrap ClassLoader，这个加载链，就保证了 Object 不会被重复加载。
4. 如果 BoostrapClassLoader，没有加载成功，就会调用自己的 findClass 方法由自己来对类进行加载，findClass 加载类的地址是自己本 web 应用下的 class。
5. **加载依然失败，才使用 AppClassLoader 继续加载。**
6. 都没有加载成功的话，抛出异常。

总结一下以上步骤，WebAppClassLoader 加载类的时候，故意打破了JVM 双亲委派机制，绕开了 AppClassLoader，直接先使用 ExtClassLoader 来加载类。

- 保证了基础类不会被同时加载。
- 又保证了在同一个 Tomcat 下不同 web 之间的 class 是相互隔离的。



### 5、cms收集器过程，g1收集器原理，怎么实现可预测停顿的，region的大小结构？

CMS 处理过程有七个步骤：

1. 初始标记(CMS-initial-mark) ,会导致stw;
2. 并发标记(CMS-concurrent-mark)，与用户线程同时运行；
3. 预清理（CMS-concurrent-preclean），与用户线程同时运行；
4. 可被终止的预清理（CMS-concurrent-abortable-preclean） 与用户线程同时运行；
5. 重新标记(CMS-remark) ，会导致swt；
6. 并发清除(CMS-concurrent-sweep)，与用户线程同时运行；
7. 并发重置状态等待下次CMS的触发(CMS-concurrent-reset)，与用户线程同时运行； 其运行流程图如下所示：





### 6、内存溢出，内存泄漏遇到过吗？什么场景产生的，怎么解决的？

引起内存溢出的原因有很多种，常见的有以下几种：
　　1.内存中加载的数据量过于庞大，如一次从数据库取出过多数据；
　　2.集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；
　　3.代码中存在死循环或循环产生过多重复的对象实体；
　　4.使用的第三方软件中的BUG；
　　5.启动参数内存值设定的过小；

【情况一】：
`java.lang.OutOfMemoryError:Javaheapspace`：这种是java堆内存不够，一个原因是真不够（如递归的层数太多等），另一个原因是程序中有死循环；
　　如果是java堆内存不够的话，可以通过调整JVM下面的配置来解决：
　　-Xms3062m
　　-Xmx3062m

【情况二】
`java.lang.OutOfMemoryError:GCoverheadlimitexceeded`
　　【解释】：JDK6新增错误类型，当GC为释放很小空间占用大量时间时抛出；一般是因为堆太小，导致异常的原因，没有足够的内存。
　　【解决方案】：
　　1、查看系统是否有使用大内存的代码或死循环；
　　2、通过添加JVM配置，来限制使用内存：
　　-XX:-UseGCOverheadLimit

【情况五】：
　　java.lang.OutOfMemoryError:unabletocreatenewnativethread
　　【原因】：Stack空间不足以创建额外的线程，要么是创建的线程过多，要么是Stack空间确实小了。
　　【解决】：由于JVM没有提供参数设置总的stack空间大小，但可以设置单个线程栈的大小；而系统的用户空间一共是3G，
　　　　　　　除了Text/Data/BSS/MemoryMapping几个段之外，Heap和Stack空间的总量有限，是此消彼长的。因此遇到这个错误，
　　　　　　  可以通过两个途径解决：1.通过-Xss启动参数减少单个线程栈大小，这样便能开更多线程（当然不能太小，太小会出现StackOverflowError）；
　　　　　　　　　　　　　　　　　　2.通过-Xms-Xmx两参数减少Heap大小，将内存让给Stack（前提是保证Heap空间够用）。

【情况六】：
　　java.lang.StackOverflowError
　　【原因】：这也内存溢出错误的一种，即线程栈的溢出，要么是方法调用层次过多（比如存在无限递归调用），要么是线程栈太小。
　　【解决】：优化程序设计，减少方法调用层次；调整-Xss参数增加线程栈大小

Java都采用了“可达性分析”算法来进行内存回收，原理是：会有几个引用作为root节点，对于任意对象来说，如果从root层层遍历，如果找不到对于他的引用链，那么这个对象就被标记为无用，就会在gc时被销毁。









### 7、volatile的原理？synchronized和重入锁实现原理以及区别？

volatile保证**可见性**、**防止指令重排**，不保证**原子性**。在JVM底层volatile是采用“内存屏障”来实现的。













### 8、redis字符串实现，sds和c字符串区别？

**1、在求长度的时候**   C字符串 O(n)  SDS只需要访问len属性即可 时间复杂度O(1).
**2、缓冲区溢出问题**   C字符串会修改与它相邻 SDS 这里会先根据空间是否够用,实际空间长度为 free + len + 1 
**3、字符串内存分配**   SDS 内部使用两种机制 惰性空间释放跟空间预分配
空间预分配：这里SDS<1M的时候是 free = len,若SDS=6byte 则空间为 6byte + 6byte + 1byte     
大于1M的时候free = 1M, 若SDS长度为60M 则实际空间为 60M + 1M + 1byte
惰性空间释放  不立即使用内存重新分配来回收缩短后的字节，而是通过free记录起来，以供后续使用，SDS也提供了相应的API，防止惰性空间导致内存浪费。

### 9、redis集群，为什么是16384个slot？选举过程，会有脑裂问题么，raft算法，优缺点？

(1)如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。
如上所述，在消息头中，最占空间的是`myslots[CLUSTER_SLOTS/8]`。
当槽位为65536时，这块的大小是:
`65536÷8÷1024=8kb`
因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽。
(2)redis的集群主节点数量基本不可能超过1000个。
如上所述，集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。
那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。
(3)槽位越小，节点少的情况下，压缩比高
Redis主节点的配置信息中，它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中，会对bitmap进行压缩，但是如果bitmap的填充率slots / N很高的话(N表示节点数)，bitmap的压缩率就很低。
如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。



### 10、redis有序集合怎么实现的，跳表是什么？往跳表添加一个元素的过程获取分数的时间复杂度，为什么不用红黑树，红黑树有什么特点，左旋右旋操作？

```c
# Redis使用了两种数据结构来共同实现有序集合
typedef struct zset{
     //跳跃表
     zskiplist *zsl;		// 范围操作 查找O(logN)
     //字典
     dict *dice;				// 无序保存元素 查找O(1) 
} zset;
```

当有序集合对象同时满足以下两个条件时，对象使用 `ziplist` 编码：
1、保存的元素数量小于128；
2、保存的所有元素长度都小于64字节。

不能满足上面两个条件的使用 `skiplist` 编码。以上两个条件也可以通过Redis配置文件`zset-max-ziplist-entries` 选项和 `zset-max-ziplist-value` 进行修改。

假设我们要插入的结点是10，首先我们按照跳表查找结点的方法，找到待插入结点的前置结点（仅小于待插入结点）：

![img](../../images/37c930c77206489399169c56786dd606.png)

接下来，按照一般链表的插入方式，把结点10插入到结点9的下一个位置：

![img](../../images/9637fdae9cf545e9b561454d5311b9c6.png)

这样是不是插入工作就完成了呢？并不是。随着原始链表的新结点越来越多，索引会渐渐变得不够用了，因此索引结点也需要相应作出调整。

如何调整索引呢？我们让新插入的结点随机“晋升”，也就是成为索引结点。**新结点晋升成功的几率是50%。**

假设第一次随机的结果是晋升成功，那么我们把结点10作为索引结点，插入到第1层索引的对应位置，并且向下指向原始链表的结点10：

![img](../../images/7900200883c844b48f00beb22c4cb396.png)

新结点在成功晋升之后，仍然有机会继续向上一层索引晋升。我们再进行一次随机，假设随机的结果是晋升失败，那么插入操作就告一段落了。

小灰说的是什么意思呢？让我们看看下图， 新结点10已经晋升到第2层索引，下一次随机的结果仍然是晋升成功，这时候该怎么办呢？

![img](../../images/9eb747d7eb504e4aa3c8fffd09aa1e33.png)

![img](../../images/fdb807a921d44fb49a6e06909726090d.png)

![img](../../images/07bdf3513f104153a8dfda29d6f8e220.png)



Redis之所以使用跳表而不使用红黑树原因如下：
	1.实现简单，相对于红黑树来说，**实现更加的简单**，不容易出错，代码更加容易维护和调试。
	2.跳表的**底层节点**有都是通过**双向指针相互链接**，这和B+树一样，对于范围查找会更加的方便。
	3.跳表的效率和红黑树一样，**查找单个Key时间复杂度都是O(logn)**
	4.跳表更加灵活，可以通过改变索引构建策略，有效的平衡执行效率和内存消耗。

| zrangebyscore<br />zrevrangebyscore | O(log(n)+k)，k为要获取成员个数，n为当前成员个数 |
| ----------------------------------- | ----------------------------------------------- |
| zadd                                | O(k*log(n))，k为添加 成员个数，n为当前成员个数  |
|                                     |                                                 |

### 11、锁升级过程，轻量锁可以变成偏向锁么？偏向锁可以变成无锁么？对象头结构，锁状态变化过程？

**锁可以升级但不能降级**，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率.

如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。偏向锁通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。一旦有第二个线程加入锁竞争，偏向锁就升级为轻量级锁（自旋锁）。升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致STW(stop the word)操作； 

> 锁竞争：如果多个线程轮流获取一个锁，但是每次获取锁的时候都很顺利，没有发生阻塞，那么就不存在锁竞争。只有当某线程尝试获取锁的时候，发现该锁已经被占用，只能等待其释放，这才发生了锁竞争。

**轻量级锁（自旋锁）**

> 自旋锁：自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。

在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。长时间的自旋操作是非常消耗资源的，一个线程持有锁，其他线程就只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做忙等（busy-waiting）。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁。

### 12、Innodb的结构了解么？磁盘页和缓存区是怎么配合的？缓冲区和磁盘数据不一致怎么办，服务器突然宕机了数据会丢失么？

MySQL底层架构，涉及到：

- **内存结构**：`buffer pool`、`log buffer`、`change buffer`，buffer pool的页淘汰机制是怎样的；
- **磁盘结构**：`系统表空间`、`独立表空间`、`通用表空间`、`undo表空间`、`redo log`；
- 以及`IO`相关底层原理、查询`SQL执行流程`、数据`页结构`和`行结构`描述、`聚集索引`和`辅助索引`的底层数据组织方式、`MVCC`多版本并发控制的底层实现原理，以及可`重复读`、`读已提交`是怎么通过MVCC实现的。









### 13、InnoDB 索引为什使用B+树而不是用B树？

**B+树只有叶节点存放数据，其余节点用来索引，而B-树是每个索引节点都会有Data域。**所以从Mysql（Inoodb）的角度来看，B+树是用来充当索引的，一般来说索引非常大，尤其是关系性数据库这种数据量大的索引能达到亿级别，所以为了减少内存的占用，索引也会被存储在磁盘上。 

**那么Mysql如何衡量查询效率呢？– 磁盘IO次数。** B-树/B+树 的特点就是每层节点数目非常多，层数很少，目的就是为了就少磁盘IO次数，但是B-树的每个节点都有data域（指针），这无疑增大了节点大小，说白了增加了磁盘IO次数（磁盘IO一次读出的数据量大小是固定的，单个数据变大，每次读出的就少，IO次数增多，一次IO多耗时），而B+树除了叶子节点其它节点并不存储数据，节点小，磁盘IO次数就少。**这是优点之一。** 
**另一个优点是：** B+树所有的Data域在叶子节点，一般来说都会进行一个优化，就是**将所有的叶子节点用指针串起来**。这样**遍历**叶子节点就能获得全部数据，这样就能进行区间访问啦。在数据库中基于范围的查询是非常频繁的，而B树不支持这样的遍历操作。

B树相对于红黑树的区别

**AVL 数和红黑树基本都是存储在内存中才会使用的数据结构**。在大规模数据存储的时候，红黑树往往出现由于**树的深度过大**而造成磁盘IO读写过于频繁，进而导致效率低下的情况。为什么会出现这样的情况，我们知道要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。根据**磁盘查找存取的次数往往由树的高度所决定**，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树可以有多个子女，从几十到上千，可以降低树的高度。

**数据库系统的设计者巧妙利用了磁盘预读原理**，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证**一个节点物理上也存储在一个页里**，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。

### 14、MySQL 分表是怎么实现的？跨库join如何解决？数据量突增怎么解决？





### 15、数据库的隔离级别，怎么实现的？当前读，快照读？MVCC？ 

### 16、mysql优化的实践经验 





### 17、分布式事务出现过不一致吗？为什么？怎么解决？有什么方法避免？怎么监控？监控到怎么处理？什么时候需要人工接入？



### 18、io模型了解么？多路复用？selete，poll，epoll，epoll的结构？怎么注册事件？



### 19、你们用的什么消息中间件，kafka，为什么用kafka？kafka是怎么保证高吞吐量的？





**kafka是怎么保证高吞吐量的**

**1.顺序读写**

kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能。顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写。
生产者负责写入数据，Kafka会将消息持久化到磁盘，保证不会丢失数据，Kafka采用了俩个技术提高写入的速度。
**1.顺序写入**：如果是随机IO，磁盘会进行频繁的寻址，导致写入速度下降。Kafka使用了顺序IO提高了磁盘的写入速度，Kafka会将数据顺序插入到文件末尾，消费者端通过控制**偏移量**来读取消息，这样做会导致数据无法删除，时间一长，磁盘空间会满，kafka提供了2种策略来删除数据：基于时间删除和基于partition文件的大小删除。
**2.Memory Mapped Files**：这个和Java NIO中的内存映射基本相同，在大学的计算机原理里我们学过（划重点），mmf直接利用操作系统的Page来实现文件到物理内存的映射，完成之后对物理内存的操作会直接同步到硬盘。mmf通过内存映射的方式大大提高了IO速率，省去了用户空间到内核空间的复制。它的缺点显而易见--不可靠，当发生宕机而数据未同步到硬盘时，数据会丢失，Kafka提供了produce.type参数来控制是否主动的进行刷新，如果kafka写入到mmp后立即flush再返回给生产者则为同步模式，反之为异步模式。

**2.零拷贝**

在这之前先来了解一下零拷贝(直接让操作系统的 Cache 中的数据发送到网卡后传输给下游的消费者)：平时从服务器读取静态文件时，服务器先将文件从复制到内核空间，再复制到用户空间，最后再复制到内核空间并通过网卡发送出去，而零拷贝则是直接从内核到内核再到网卡，省去了用户空间的复制。
Kafka把所有的消息存放到一个文件中，当消费者需要数据的时候直接将文件发送给消费者，比如10W的消息共10M，全部发送给消费者，10M的消息在内网中传输是非常快的，假如需要1s，那么kafka的tps就是10w。Zero copy对应的是Linux中sendfile函数，这个函数会接受一个offsize来确定从哪里开始读取。现实中，不可能将整个文件全部发给消费者，他通过消费者传递过来的偏移量来使用零拷贝读取指定内容的数据返回给消费者。

在Linux kernel2.2 之后出现了一种叫做"零拷贝(zero-copy)"系统调用机制，就是跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”，系统上下文切换减少为2次，可以提升一倍的性能。

![img](../../images/webp)

**3.分区**

kafka中的topic中的内容可以被分为多分partition存在,每个partition又分为多个段segment,所以每次操作都是针对一小部分做操作，很轻便，并且增加`并行操作`的能力

**4.批量发送**

kafka允许进行批量发送消息，producter发送消息的时候，可以将消息缓存在本地,等到了固定条件发送到kafka

1. 等消息条数到固定条数
2. 一段时间发送一次

**5.数据压缩**

Kafka还支持对消息集合进行压缩，Producer可以通过GZIP或Snappy格式对消息集合进行压缩。
压缩的好处就是减少传输的数据量，减轻对网络传输的压力。

Producer压缩之后，在Consumer需进行解压，虽然增加了CPU的工作，但在对大数据处理上，瓶颈在网络上而不是CPU，所以这个成本很值得*`批量发送`和`数据压缩`一起使用,单条做数据压缩的话，效果不明显*

 

Kafka的设计目标是高吞吐量，它比其它消息系统快的原因体现在以下几方面：

1、Kafka操作的是序列文件I / O（序列文件的特征是按顺序写，按顺序读），为保证顺序，Kafka强制点对点的按顺序传递消息，这意味着，一个consumer在消息流（或分区）中只有一个位置。

2、Kafka不保存消息的状态，即消息是否被“消费”。一般的消息系统需要保存消息的状态，并且还需要以随机访问的形式更新消息的状态。而Kafka 的做法是保存Consumer在Topic分区中的位置offset，在offset之前的消息是已被“消费”的，在offset之后则为未“消费”的，并且offset是可以任意移动的，这样就消除了大部分的随机IO。

3、Kafka支持点对点的批量消息传递。

4、Kafka的消息存储在OS pagecache（页缓存，page cache的大小为一页，通常为4K，在Linux读写文件时，它用于缓存文件的逻辑内容，从而加快对磁盘上映像和数据的访问）。



### 20、kafka重平衡，重启服务怎么保证kafka不发生重平衡，有什么方案？







### 21、netty的原理和使用？tcp的连接过程？一台服务器能支持多少连接，为什么 ？tcp各个参数怎么设置？



**服务端**

我们现在在来回头考虑服务器端。对于服务器来说，最大支持的并发连接是多少呢？就有人开始可爱地糊涂了：“服务器端理论也是端口限制吗？”。好，假设如果受影响的话，那我们的Nginx服务器只监听了一个80端口。那Nginx只能接受一个TCP连接喽？这明显是太荒唐了。

好，我们再看另外一个靠谱一点的答案。那就是一条TCP连接是由一个四元组组成的。不考虑地址重用（unix的SO_REUSEADDR选项）的情况下，对于我们这台Nginx Server来说，它的IP和端口是固定的。cp连接4元组中只有remote ip（也就是client ip）和remote port（客户端port）是可变的。它可能建立的最大的连接数是2的32次方（ip数）×2的16次方（port数）。这是2.8*10的14次方的一个大数字，两百万亿！！

Linux上除了监听80以外，还可以监听其它的端口，例如Mysql的3306, Redis的6339，当然所有65535个端口你都可以用来监听一遍。这样理论上线就到了2的32次方（ip数）×2的16次方（port数）×2的16次方（服务器port数）个。感兴趣你可以算一下，这个基本相当于无穷个了。

不过理想和实际总是会有差距的，因为Linux每维护一条TCP连接都要花费资源。处理连接请求，保活，数据的收发时需要消耗一些CPU，维持TCP连接主要消耗内存。我们题目的问题是考虑最大多少个连接，所以我们先不考虑数据的收发。那么TCP在静止的状态下，就不怎么消耗CPU了，主要消耗内存。而Linux上内存是有限的。
我们今天先直接把结论抛出来，一条TCP连接如果不发送数据的话，消耗内存是3.3K左右。如果有数据发送，需要为每条TCP分配发送缓存区，大小受你的参数net.ipv4.tcp_wmem配置影响，默认情况下最小是4K。如果发送结束，缓存区消耗的内存会被回收详细的分析过程敬请期待接下来的另一篇文章。

**假设你只保持连接不发送数据，那么你服务器可以建立的连接最大数量 = 你的内存/3.3K。** 假如是4GB的内存，那么大约可接受的TCP连接数量是100万左右。

> 这个例子里，我们考虑的前提是在一个进程下hold所有的服务器端连接。而在实际中的项目里，为了收发数据方便，很多网络IO模型还会为TCP连接再创建一个线程或协程。拿最轻量的golang来说，一个协程栈也需要2KB的内存开销。

**结论**

一台机器最大究竟能支持多少个网络连接？这个简单的问题里其实埋了坑，导致无数的英雄好汉被困惑不解。就和树上九只鸟打死一只还剩几只的问题一样，没有和你说清楚树上是真鸟，还是假鸟。也没有说枪是有声还是无声的。通过今天的分析，相信你终于可以扬眉吐气把这个问题踩在脚下摩擦了。来，总结下：

- **TCP连接的客户端机：**每一个ip可建立的TCP连接理论受限于内核net.ip_local_port_range参数，也受限于65535。但可以通过配置多ip的方式来加大自己的建立连接的能力。
- **TCP连接的服务器机：**每一个监听的端口虽然理论值很大，但这个数字没有实际意义。最大并发数取决你的内存大小，每一条静止状态的TCP连接大约需要吃3.3K的内存。



### 22、Sping的AOP实现原理，以及对象生成方式的种类，单例的还是原型的？





### 23、讲讲调度接口是怎么实现的

Timer 的设计核心是一个 TaskQueue 和一个 TimerThread。Timer 将接收到的任务丢到自己的 TaskQueue中。TimerThread 在创建 Timer 时会启动成为一个守护线程。这个线程会轮询所有任务，找到一个最近要执行的任务，然后休眠，当到达最近要执行任务的开始时间点，TimerThread 被唤醒并执行该任务。之后 TimerThread 更新最近一个要执行的任务，继续休眠。



### 24、分布式唯一ID是怎么实现的





### 25、设计模式，以及自己使用的场景





### 26、有没有用过分布式锁，怎么实现的，讲讲原理 





### 27、如何解决线上问题？cpu狂飙怎么办？频繁minor gc怎么办？可能造成的原因是什么？如何避免？





### 28、怎么理解分布式和微服务，为什么要拆分服务，会产生什么问题，怎么解决这些问题 ？

**面试题剖析**

**为什么要将系统进行拆分？**

网上查查，答案极度零散和复杂，很琐碎，原因一大坨。但是我这里给大家直观的感受：

1.代码量大，容易冲突，合并非常耗费时间
2.不敢随意乱改技术。

**拆分了以后**，每个人维护自己的服务就可以了。技术上想怎么升级就怎么升级，大幅度提升复杂系统大型团队的开发效率

**拆分后不用 dubbo 可以吗？**

当然可以了，大不了最次，就是各个系统之间，直接基于 spring mvc，就纯 http 接口互相通信呗，还能咋样。但是这个肯定是有问题的，因为 http 接口通信维护起来成本很高，你要考虑**超时重试**、**负载均衡**等等各种乱七八糟的问题，比如说你的订单系统调用商品系统，商品系统部署了 5 台机器，你怎么把请求均匀地甩给那 5 台机器？这不就是负载均衡？你要是都自己搞那是可以的，但是确实很痛苦。

所以 dubbo 说白了，是一种 rpc 框架，就是说本地就是进行接口调用，但是 dubbo 会代理这个调用请求，跟远程机器网络通信，给你处理掉负载均衡了、服务实例上下线自动感知了、超时重试了，等等乱七八糟的问题。那你就不用自己做了，用 dubbo 就可以了。



### 29、怎么理解高可用，如何保证高可用，有什么弊端，熔断机制，怎么实现 ？







### 30、对于高并发怎么看，怎么算高并发，你们项目有么，如果有会产生什么问题，怎么解决





###   

31、有没有做过压测的项目？首页接口优化是怎么做的？
32、如何优雅的写代码？什么代码算做优雅？什么代码是规范？你们代码规范是什么样的？如何进行code review？ 
33、算法：给定一个长度为N的整形数组arr，其中有N个互不相等的自然数1-N，请实现arr的排序，但是不要把下标0∼N−1位置上的数通过直接赋值的方式替换成1∼N
34、算法：判断一个树是否是平衡二叉树
35、算法：给定一个二叉树，请计算节点值之和最大的路径的节点值之和是多少，这个路径的开始节点和结束节点可以是二叉树中的任意节点
36、算法：LRU 缓存
37、算法：实现带有getMin功能的栈，要求push，pop，getMin的时间复杂度都是O(1)
38、算法：两数之和
39、算法：实现二叉树先序，中序和后序遍历