# 2.8.2 面试官：为什么redis不能保证100%数据不丢失

`Redis` 在以下 2 个场景下，都会导致数据丢失。
`AOF` 持久化配置为每秒写盘，但这个写盘过程是异步的，`Redis` 宕机时会存在数据丢失的可能
主从复制也是异步的，主从切换时，也存在丢失数据的可能（从库还未同步完成主库发来的数据，就被提成主库）
基于以上原因我们可以看到，`Redis` 本身的无法保证严格的数据完整性。
所以，如果把 `Redis` 当做消息队列，在这方面是有可能导致数据丢失的。

再来看那些专业的消息队列中间件是如何解决这个问题的？
像 `RabbitMQ` 或 `Kafka` 这类专业的队列中间件，在使用时，一般是部署一个集群，生产者在发布消息时，队列中间件通常会写`多个节点`，以此保证消息的完整性。这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。
也正因为如此，`RabbitMQ、Kafka`在设计时也更复杂。毕竟，它们是专门针对队列场景设计的。
但 `Redis` 的定位则不同，它的定位更多是当作缓存来用，它们两者在这个方面肯定是存在差异的。

### 1.4.4 消息积压怎么办

因为 `Redis` 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 `Redis` 的内存持续增长，如果超过机器内存上限，就会面临被 `OOM` 的风险。
所以，`Redis` 的 `Stream` 提供了可以指定队列最大长度的功能，就是为了避免这种情况发生。
但 `Kafka、RabbitMQ` 这类消息队列就不一样了，它们的数据都会存储在磁盘上，磁盘的成本要比内存小得多，当消息积压时，无非就是多占用一些磁盘空间，相比于内存，在面对积压时也会更加坦然

综上，我们可以看到，把 `Redis` 当作队列来使用时，始终面临的 2 个问题：

- `Redis` 本身可能会丢数据
- 面对消息积压，`Redis` 内存资源紧张

到这里，`Redis` 是否可以用作队列，我想这个答案你应该会比较清晰了。
如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。
